<section class="success" id="papers">
  <div class="container">
    <div class="row">
      <div class="col-lg-12 text-center">
        <h2>Call For Papers</h2>
        <hr class="star-light">
      </div>
    </div>
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 text-center">
        <p>We invite submissions in two formats: extended abstracts (1-8 pages), or slides (15-20 slides). By accepting slides, we hope to lower the writing burden for industry participants. However, since slides submissions sometimes are short on details, we might request clarification or additional editing as condition for acceptance. We encourage contributions in new theoretical research, practical solutions to particular aspects of scaling a recommender, best practices in scaling evaluation systems, and creative new applications of big data to large scale recommendation systems.</p>

        <p>Our topics of interests include, but are not limited to:</p>
        <div class="col-lg-12 text-left">
        <ul>

        <li><b>Large Foundational Models and Large User Representations</b>: Exploring techniques in large user-modeling and learning large foundational models that adapt well to highly dynamic environments and scale well with content and users. Enabling adaptive and real-time learning and optimization of recommendations in the face of fast evolving user-preferences and content uploads.</li>

        <li><b>Large Language Models (LLM) for Recommendations</b>: Exploring the utilization of LLM to enhance recommendation systems, leveraging natural language understanding to generate personalized suggestions across various content domains.</li>

        <li><b>Scalability and Efficiency</b>: Investigating and discussing system architectures and optimizations that effectively process billions of interactions, and ensure efficiency in model training, serving and updates.</li>

        <li><b>Data Sparsity and Cold-start</b>: Developing data-efficient methods to deal with the lack of user or item data to improve large-scale recommendations in data sparse environments.</li>

        <li><b>Fairness and Bias in Large Ecosystems</b>: Designing large recommender systems that address issues of algorithmic bias, and promote diversity and fairness.</li>

        <li><b>Evaluation and and Experimentation</b>: Establishing online and offline metrics and algorithms to measure user satisfaction and ecosystem objectives, going far beyond the classic offline accuracy-based measures. Discussing offline and online iteration and experimentation frameworks to test at scale efficiently and reduce data pollution and leakage.</li>

        <li><b>RecSys MLOps</b>: Streamlining model deployment, monitoring and retraining to ensure the performance and stability of production-scale recommender systems.</li>
        </ul></div>

        <a href="https://easychair.org/conferences2/submissions?a=32785002" class="btn btn-primary btn-xl page-scroll">Add Submission</a>



      </div>
    </div>
  </div>
</section>
